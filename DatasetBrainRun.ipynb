{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Cata Sample tem 15-20 mili segundos |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Criação da leitura e mapeamento dos dados de 1 json | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n",
    "from itertools import zip_longest\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "f = open('sensors/0ge7rd5_1536666246388.json')\n",
    "data = json.load(f)\n",
    "with open('sensors/0f4uezb_1541637607517.json', 'r') as json_data:\n",
    "   gay = json.load(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Printar Json na tela |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Usar normalize para verificar parametros/tipos de label do json |\n",
    "\n",
    "Dataset divido em :\n",
    "\n",
    "player_id\t: id\n",
    "\n",
    "accelerometer\t: z,x,y, screen\n",
    "\n",
    "gyroscope\t: z,x,y, screen\n",
    "\n",
    "deviceMotion\t: z,x,y, screen\n",
    "\n",
    "magnetometer : z,x,y, screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = json_normalize(data)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Verificar quais dados são passados mudando por tipo do parametro solicitado, não são os mesmos. |\n",
    "\n",
    "criação de 1 data frame unico para visualização por camadas/ quantidade de dados\n",
    "\n",
    "No exemplo são tirados 197 dados em cada parametroata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['accelerometer'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['accelerometer']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Inicio da criação da analize de quantificação e time Stemp |\n",
    "\n",
    "y = lista dos nomes dos usuarios\n",
    "\n",
    "names_to_skip = filtragem dos dados por nome\n",
    "\n",
    "number = \"\"\n",
    "\n",
    "sem, z = limpagem de nome apenas\n",
    "\n",
    "all_files = leitura dos arquivos\n",
    "\n",
    "todos = lista de todos os usuarios sem o timestemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n",
    "from itertools import zip_longest\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "all_files = glob.glob('sensors/*_*.json')\n",
    "y = []\n",
    "names_to_skip = []\n",
    "number = []\n",
    "todos =[]\n",
    "x = 0\n",
    "for file in all_files:\n",
    "    name = file.split('\\\\')[1].split('.')[0]\n",
    "    first_name = name.split('_')[0]\n",
    "    sem = name.split('_')[0]\n",
    "    todos.append(sem)\n",
    "    if first_name not in names_to_skip:\n",
    "        names_to_skip.append(first_name)\n",
    "        x=x+1\n",
    "        z = name.split('_')[0]\n",
    "        y.append(z)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Criar a lista de da quantidade repetida de cada usuario |\n",
    "\n",
    "utilizando o repeat para visualizar em 'y' os nomes de usuarios e contar comparando com os valores em 'todos' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "lista = []\n",
    "for repeat in y:\n",
    "    contagem = todos.count(repeat)\n",
    "    lista.append(contagem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Criar extensão da lista de usuario e quantidade de times stemp |\n",
    "\n",
    "Cada sample da timestemp é tirada entre 15-20 ms\n",
    "\n",
    "extenção = lista matriz usuario e quantidade\n",
    "\n",
    "\n",
    "cria arquivo quantidade de timestemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "extencao = list(zip_longest(y, lista, fillvalue=''))\n",
    "extencao\n",
    "\n",
    "with open(r'quantidade de arquivos.txt', 'w') as fp:\n",
    "    for item in extencao:\n",
    "        fp.write(\"%s %i\\n\" % item)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extencao "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Quantidade total dos dados |\n",
    "contador = contar o valor total no objeto 'lista'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador = 0\n",
    "for help in lista:\n",
    "    contador = contador + help\n",
    "contador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Plotagem do graficos useer e quantidade de timeStemp. |\n",
    "\n",
    "o = é uma lista semelhante apenas de quantificação para o valor total (pode ser retirado)\n",
    "\n",
    "\n",
    "\"jacare\" é so o nome do for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = []\n",
    "cara = 0\n",
    "for jacare in y:\n",
    "    cara = cara +1\n",
    "    o.append(cara)\n",
    "lista_n= sorted(lista)\n",
    "fig,ax = plt.subplots()\n",
    "plt.figure(figsize=(9, 5.5))\n",
    "plt.xlim(0,1132)\n",
    "plt.ylim(0,1000)\n",
    "plt.bar(o,lista_n)\n",
    "plt.xlabel(\"Users\",fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel(\"Quantity of timestamps\", fontsize = 20)\n",
    "sns.set_context(\"paper\", font_scale=0)  \n",
    "plt.savefig(\"quantidade de usuarios por times temp.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| CRIAR TXT DE CADA USUARIO POR QUANTIDADE DE TIMESTEMP |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.read_csv('quantidade de arquivos.txt', sep =\" \")\n",
    "\n",
    "for zero in lista:\n",
    "    new = pf.loc[pf['quantidade_timestemp'] == zero]\n",
    "    val = len(new)\n",
    "    tam =str(val)\n",
    "    nominho = str(zero)\n",
    "\n",
    "    with open(r''+tam+ 'users '+ nominho +'timers.txt', 'w') as fp:\n",
    "        fp.write(str(new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Escolha do menor numero de Timestemp |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.read_csv('quantidade de arquivos.txt', sep =\" \")\n",
    "exemplo = pf.loc[pf['quantidade_timestemp'] == 1]\n",
    "exemplo2 = pf.loc[pf['quantidade_timestemp'] == 2]\n",
    "exemplo3 = pf.loc[pf['quantidade_timestemp'] == 3]\n",
    "exemplo4 = pf.loc[pf['quantidade_timestemp'] == 4]\n",
    "exemplo5 = pf.loc[pf['quantidade_timestemp'] == 5]\n",
    "exemplo6 = pf.loc[pf['quantidade_timestemp'] == 6]\n",
    "exemplo789 = pf.loc[pf['quantidade_timestemp'].isin(range(1,7904))]\n",
    "onestemp = exemplo['user'].values\n",
    "onestemp2 = exemplo2['user'].values\n",
    "onestemp3 = exemplo3['user'].values\n",
    "onestemp4 = exemplo4['user'].values\n",
    "onestemp5 = exemplo5['user'].values\n",
    "onestemp6 = exemplo6['user'].values\n",
    "onestemp7 = exemplo789['user'].values\n",
    "len(onestemp7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(onestemp7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| preguiça de pensar um codigo para estrair do dataframe |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onestemp1 =['0dhpckv', '0f4uezb','0yx7i56','1dip0jt','1tnew6a','2vv6lsy','3f2txh','4arhrqa','4rk17kc','5i52scp','654f8mn','6671xdz','6qrtzb2','6v3c51r','7u5klrb','8bi324','9jiir43','b4dnqru','d4ydsnq','d52s5qy','dici8pg','e651oif','f0lxlyl','f4tp67x','feglfhj','g5dfles','hvvzcv5','j3as74z','jlx3rg4','kqmsnvb','kwlh67i','l0qgb1b','lfqxp4u','lqxz7nk','m4k0ppn','mfg63ja','nvxrplm','ooq9btt','pgfm0e5','plfzjjx','r05vewv','r883oye','r92spr6','srekxpz','t0p185n','x5z8t9c','xamvmms','yenehau','ylocu2a','yv6n8gx','zcmg3s9','zyt437w']\n",
    "len(onestemp1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Leitura de json e retirada do tamanho das samples |\n",
    "\n",
    "Retirar o nome da lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tentando = []\n",
    "all_files = glob.glob('sensors/*_*.json')\n",
    "for file in all_files:\n",
    "    name = file.split('_')[1]\n",
    "    jon = name.split('.')[0]\n",
    "    tentando.append(jon)\n",
    "tentando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tentando)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tentando)\n",
    "f = open('sensors/4fgo39z_1543696166413.json')\n",
    "data = json.load(f)\n",
    "df = pd.DataFrame(data['gyroscope'])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Adaptação do codigo anterior parra todos os arquivos |\n",
    "\n",
    "onestemp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_samplegy =[]\n",
    "q_sampleacc =[]\n",
    "q = 0\n",
    "h = 0\n",
    "b=0\n",
    "onestempname = []\n",
    "for i in onestemp:\n",
    "    for j in tentando:\n",
    "        json_files = glob.glob('sensors/'+i+'_'+j+'.json')\n",
    "        for file in json_files:\n",
    "            x = 'sensors/'+i+'_'+j+'.json'\n",
    "            if  x == file:\n",
    "                onestempname.append(i)\n",
    "                b = b+1\n",
    "                h = b/len(onestemp)\n",
    "                print(h,\"%\")\n",
    "                f = open('sensors/'+i+'_'+j+'.json')\n",
    "                data = json.load(f)\n",
    "                df = pd.DataFrame(data['gyroscope'])\n",
    "                q = len(df)\n",
    "                q_samplegy.append(q)\n",
    "                df = pd.DataFrame(data['accelerometer'])\n",
    "                q = len(df)\n",
    "                q_sampleacc.append(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Desenvolver timestemp = 2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_samplegy2 =[]\n",
    "q_sampleacc2 =[]\n",
    "qq = 0\n",
    "h = 0\n",
    "b=0\n",
    "onestemp2name = []\n",
    "timename2 =[]\n",
    "for i in onestemp2:\n",
    "    time = True\n",
    "    for j in tentando:\n",
    "        json_files = glob.glob('sensors/'+i+'_'+j+'.json')\n",
    "        if time == False:\n",
    "                break\n",
    "        for file in json_files:\n",
    "            if time == False:\n",
    "                break\n",
    "            x = 'sensors/'+i+'_'+j+'.json'\n",
    "            if  x == file:\n",
    "                if time ==True:\n",
    "                    time = False\n",
    "                onestemp2name.append(i)\n",
    "                b = b+1\n",
    "                h = b/(len(onestemp2))\n",
    "                print(h,\"%\")\n",
    "                f = open('sensors/'+i+'_'+j+'.json')\n",
    "                data = json.load(f)\n",
    "                df = pd.DataFrame(data['gyroscope'])\n",
    "                q = len(df)\n",
    "                q_samplegy2.append(q)\n",
    "                df = pd.DataFrame(data['accelerometer'])\n",
    "                q = len(df)\n",
    "                q_sampleacc2.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_samplegy3 =[]\n",
    "q_sampleacc3 =[]\n",
    "q = 0\n",
    "h = 0\n",
    "b = 0\n",
    "onestemp3name = []\n",
    "timename3 =[]\n",
    "for i in onestemp3:\n",
    "    time = True\n",
    "    for j in tentando:\n",
    "        json_files = glob.glob('sensors/'+i+'_'+j+'.json')\n",
    "        if time == False:\n",
    "                break\n",
    "        for file in json_files:\n",
    "            if time == False:\n",
    "                break\n",
    "            x = 'sensors/'+i+'_'+j+'.json'\n",
    "            if  x == file:\n",
    "                if time ==True:\n",
    "                    time = False\n",
    "                onestemp3name.append(i)\n",
    "                b = b+1\n",
    "                h = b/(len(onestemp3))\n",
    "                print(h,\"%\")\n",
    "                f = open('sensors/'+i+'_'+j+'.json')\n",
    "                data = json.load(f)\n",
    "                df = pd.DataFrame(data['gyroscope'])\n",
    "                q = len(df)\n",
    "                q_samplegy3.append(q)\n",
    "                df = pd.DataFrame(data['accelerometer'])\n",
    "                q = len(df)\n",
    "                q_sampleacc3.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_samplegy4 =[]\n",
    "q_sampleacc4 =[]\n",
    "q = 0\n",
    "h = 0\n",
    "b = 0\n",
    "onestemp4name = []\n",
    "timename4 =[]\n",
    "for i in onestemp4:\n",
    "    time = True\n",
    "    for j in tentando:\n",
    "        json_files = glob.glob('sensors/'+i+'_'+j+'.json')\n",
    "        if time == False:\n",
    "                break\n",
    "        for file in json_files:\n",
    "            if time == False:\n",
    "                break\n",
    "            x = 'sensors/'+i+'_'+j+'.json'\n",
    "            if  x == file:\n",
    "                if time ==True:\n",
    "                    time = False\n",
    "                onestemp4name.append(i)\n",
    "                b = b+1\n",
    "                h = b/(len(onestemp4))\n",
    "                print(h,\"%\")\n",
    "                f = open('sensors/'+i+'_'+j+'.json')\n",
    "                data = json.load(f)\n",
    "                df = pd.DataFrame(data['gyroscope'])\n",
    "                q = len(df)\n",
    "                q_samplegy4.append(q)\n",
    "                df = pd.DataFrame(data['accelerometer'])\n",
    "                q = len(df)\n",
    "                q_sampleacc4.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_samplegy5 =[]\n",
    "q_sampleacc5 =[]\n",
    "q = 0\n",
    "h = 0\n",
    "b = 0\n",
    "onestemp5name = []\n",
    "timename5 =[]\n",
    "for i in onestemp5:\n",
    "    time = True\n",
    "    for j in tentando:\n",
    "        json_files = glob.glob('sensors/'+i+'_'+j+'.json')\n",
    "        if time == False:\n",
    "                break\n",
    "        for file in json_files:\n",
    "            if time == False:\n",
    "                break\n",
    "            x = 'sensors/'+i+'_'+j+'.json'\n",
    "            if  x == file:\n",
    "                if time ==True:\n",
    "                    time = False\n",
    "                onestemp5name.append(i)\n",
    "                b = b+1\n",
    "                h = b/(len(onestemp5))\n",
    "                print(h,\"%\")\n",
    "                f = open('sensors/'+i+'_'+j+'.json')\n",
    "                data = json.load(f)\n",
    "                df = pd.DataFrame(data['gyroscope'])\n",
    "                q = len(df)\n",
    "                q_samplegy5.append(q)\n",
    "                df = pd.DataFrame(data['accelerometer'])\n",
    "                q = len(df)\n",
    "                q_sampleacc5.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_samplegy6 =[]\n",
    "q_sampleacc6 =[]\n",
    "q = 0\n",
    "h = 0\n",
    "b = 0\n",
    "onestemp6name = []\n",
    "timename6 =[]\n",
    "for i in onestemp6:\n",
    "    time = True\n",
    "    for j in tentando:\n",
    "        json_files = glob.glob('sensors/'+i+'_'+j+'.json')\n",
    "        if time == False:\n",
    "                break\n",
    "        for file in json_files:\n",
    "            if time == False:\n",
    "                break\n",
    "            x = 'sensors/'+i+'_'+j+'.json'\n",
    "            if  x == file:\n",
    "                if time ==True:\n",
    "                    time = False\n",
    "                onestemp6name.append(i)\n",
    "                b = b+1\n",
    "                h = b/(len(onestemp6))\n",
    "                print(h,\"%\")\n",
    "                f = open('sensors/'+i+'_'+j+'.json')\n",
    "                data = json.load(f)\n",
    "                df = pd.DataFrame(data['gyroscope'])\n",
    "                q = len(df)\n",
    "                q_samplegy6.append(q)\n",
    "                df = pd.DataFrame(data['accelerometer'])\n",
    "                q = len(df)\n",
    "                q_sampleacc6.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_samplegy7 =[]\n",
    "q_sampleacc7 =[]\n",
    "q = 0\n",
    "h = 0\n",
    "b = 0\n",
    "onestemp7name = []\n",
    "timename7 =[]\n",
    "for i in onestemp7:\n",
    "    for j in tentando:\n",
    "        json_files = glob.glob('sensors/'+i+'_'+j+'.json')\n",
    "        for file in json_files:\n",
    "            x = 'sensors/'+i+'_'+j+'.json'\n",
    "            if  x == file:\n",
    "                onestemp7name.append(i)\n",
    "                f = open('sensors/'+i+'_'+j+'.json')\n",
    "                data = json.load(f)\n",
    "                df = pd.DataFrame(data['gyroscope'])\n",
    "                q = len(df)\n",
    "                q_samplegy7.append(q)\n",
    "                df = pd.DataFrame(data['accelerometer'])\n",
    "                q = len(df)\n",
    "                q_sampleacc7.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(onestemp3name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(q_samplegy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Escrever a lista e salvar em txt |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist = list(zip_longest(onestemp1, q_samplegy, fillvalue=''))\n",
    "newlist = list(zip_longest(newlist, q_sampleacc, fillvalue=''))\n",
    "with open(r'sample gyroscope and acc.txt', 'w') as fp:\n",
    "    for item in newlist:\n",
    "        fp.write(\"%s %i\\n\" % item)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new = pd.DataFrame(new)\n",
    "new['user'] = onestempname\n",
    "new['sample_gy'] = q_samplegy\n",
    "new['sample_acc'] = q_sampleacc\n",
    "#newlist = pd.DataFrame(onestemp2name)\n",
    "#newlist1 = pd.DataFrame(q_samplegy2)\n",
    "#newlist2 = pd.DataFrame(q_sampleacc2)\n",
    "#frames =[newlist,newlist1, newlist2 ]\n",
    "#matriz = pd.concat(frames,axis = 1)\n",
    "new.to_csv('sample gyroscope and acc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| criando dataframe para os demais| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new = pd.DataFrame(new)\n",
    "new['user'] = onestemp2name\n",
    "new['sample_gy'] = q_samplegy2\n",
    "new['sample_acc'] = q_sampleacc2\n",
    "#newlist = pd.DataFrame(onestemp2name)\n",
    "#newlist1 = pd.DataFrame(q_samplegy2)\n",
    "#newlist2 = pd.DataFrame(q_sampleacc2)\n",
    "#frames =[newlist,newlist1, newlist2 ]\n",
    "#matriz = pd.concat(frames,axis = 1)\n",
    "new.to_csv('sample gyroscope and acc2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new = pd.DataFrame(new)\n",
    "new['user'] = onestemp3name\n",
    "new['sample_gy'] = q_samplegy3\n",
    "new['sample_acc'] = q_sampleacc3\n",
    "#newlist = pd.DataFrame(onestemp2name)\n",
    "#newlist1 = pd.DataFrame(q_samplegy2)\n",
    "#newlist2 = pd.DataFrame(q_sampleacc2)\n",
    "#frames =[newlist,newlist1, newlist2 ]\n",
    "#matriz = pd.concat(frames,axis = 1)\n",
    "new.to_csv('sample gyroscope and acc3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new = pd.DataFrame(new)\n",
    "new['user'] = onestemp4name\n",
    "new['sample_gy'] = q_samplegy4\n",
    "new['sample_acc'] = q_sampleacc4\n",
    "#newlist = pd.DataFrame(onestemp2name)\n",
    "#newlist1 = pd.DataFrame(q_samplegy2)\n",
    "#newlist2 = pd.DataFrame(q_sampleacc2)\n",
    "#frames =[newlist,newlist1, newlist2 ]\n",
    "#matriz = pd.concat(frames,axis = 1)\n",
    "new.to_csv('sample gyroscope and acc4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new = pd.DataFrame(new)\n",
    "new['user'] = onestemp5name\n",
    "new['sample_gy'] = q_samplegy5\n",
    "new['sample_acc'] = q_sampleacc5\n",
    "#newlist = pd.DataFrame(onestemp2name)\n",
    "#newlist1 = pd.DataFrame(q_samplegy2)\n",
    "#newlist2 = pd.DataFrame(q_sampleacc2)\n",
    "#frames =[newlist,newlist1, newlist2 ]\n",
    "#matriz = pd.concat(frames,axis = 1)\n",
    "new.to_csv('sample gyroscope and acc5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new = pd.DataFrame(new)\n",
    "new['user'] = onestemp6name\n",
    "new['sample_gy'] = q_samplegy6\n",
    "new['sample_acc'] = q_sampleacc6\n",
    "#newlist = pd.DataFrame(onestemp2name)\n",
    "#newlist1 = pd.DataFrame(q_samplegy2)\n",
    "#newlist2 = pd.DataFrame(q_sampleacc2)\n",
    "#frames =[newlist,newlist1, newlist2 ]\n",
    "#matriz = pd.concat(frames,axis = 1)\n",
    "new.to_csv('sample gyroscope and acc6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new = pd.DataFrame(new)\n",
    "new['user'] = onestemp7name\n",
    "new['sample_gy'] = q_samplegy7\n",
    "new['sample_acc'] = q_sampleacc7\n",
    "#newlist = pd.DataFrame(onestemp2name)\n",
    "#newlist1 = pd.DataFrame(q_samplegy2)\n",
    "#newlist2 = pd.DataFrame(q_sampleacc2)\n",
    "#frames =[newlist,newlist1, newlist2 ]\n",
    "#matriz = pd.concat(frames,axis = 1)\n",
    "new.to_csv('sample gyroscope and acc7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new = pd.DataFrame(new)\n",
    "new['user'] = onestemp7name\n",
    "new['sample_gy'] = q_samplegy7\n",
    "new['sample_acc'] = q_sampleacc7\n",
    "#newlist = pd.DataFrame(onestemp2name)\n",
    "#newlist1 = pd.DataFrame(q_samplegy2)\n",
    "#newlist2 = pd.DataFrame(q_sampleacc2)\n",
    "#frames =[newlist,newlist1, newlist2 ]\n",
    "#matriz = pd.concat(frames,axis = 1)\n",
    "new.to_csv('sample gyroscope and acc8.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Criar dataframe com valores da tiragem com accelerometro e gyroscopio|\n",
    "\n",
    "Criação do dataframe 'zeta' com a filtragem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('sample gyroscope and acc1.csv')\n",
    "#zeta = data.loc[data['sample_gy'] >=400]\n",
    "zeta = data.loc[data['sample_acc'] >=400]\n",
    "zeta = zeta.drop(['Unnamed: 0'], axis=1)\n",
    "count = 0\n",
    "#beta = q_samplegy\n",
    "#alfa = []\n",
    "#for repeated in q_samplegy:\n",
    "#    contagem = beta.count(repeated)\n",
    "#    alfa.append(contagem)\n",
    "#len(zeta)\n",
    "zeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zeta.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Grupo gama 2 timestem |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample gyroscope and acc2.csv')\n",
    "#gama = data.loc[data['sample_gy'] >=400]\n",
    "gama = data.loc[data['sample_acc'] >=400]\n",
    "gama = gama.drop(['Unnamed: 0'], axis=1)\n",
    "gama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Grupo Delta 3 timestem |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample gyroscope and acc3.csv')\n",
    "#delta = data.loc[data['sample_gy'] >=400]\n",
    "delta = data.loc[data['sample_acc'] >=400]\n",
    "delta = delta.drop(['Unnamed: 0'], axis=1)\n",
    "len(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample gyroscope and acc4.csv')\n",
    "#alfa = data.loc[data['sample_gy'] >=400]\n",
    "alfa = data.loc[data['sample_acc'] >=400]\n",
    "alfa = alfa.drop(['Unnamed: 0'], axis=1)\n",
    "len(alfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample gyroscope and acc5.csv')\n",
    "#beta = data.loc[data['sample_gy'] >=400]\n",
    "beta = data.loc[data['sample_acc'] >=400]\n",
    "beta = beta.drop(['Unnamed: 0'], axis=1)\n",
    "len(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample gyroscope and acc6.csv')\n",
    "#celta = data.loc[data['sample_gy'] >=400]\n",
    "celta = data.loc[data['sample_acc'] >=400]\n",
    "celta = celta.drop(['Unnamed: 0'], axis=1)\n",
    "len(celta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Rodrigo aqui |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample gyroscope and acc7.csv')\n",
    "#sigma = data.loc[data['sample_gy'] >=400]\n",
    "sigma = data.loc[data['sample_acc'] >=400]\n",
    "sigma = sigma.iloc[:4]\n",
    "sigma = sigma.drop(['Unnamed: 0'], axis=1)\n",
    "len(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (zeta[\"sample_gy\"].mean() + gama[\"sample_gy\"].mean() + delta[\"sample_gy\"].mean() +alfa[\"sample_gy\"].mean() + beta[\"sample_gy\"].mean() + celta[\"sample_gy\"].mean() + sigma[\"sample_gy\"].mean())/7\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Plotagem do grafico da quantidade de Gyroscopio e accelerometro |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gama.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sigma['user'].values\n",
    "s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "z = zeta['user'].values\n",
    "g = gama['user'].values\n",
    "d = delta['user'].values\n",
    "q.extend(z)\n",
    "q.extend(g)\n",
    "q.extend(d)\n",
    "z = alfa['user'].values\n",
    "g = beta['user'].values\n",
    "d = celta['user'].values\n",
    "s = sigma['user'].values\n",
    "q.extend(z)\n",
    "q.extend(g)\n",
    "q.extend(d)\n",
    "q.extend(s)\n",
    "len(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Criar txt por quantidade de Samples |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for zero in q_samplegy:\n",
    "    new = zeta.loc[zeta['sample_gy'] == zero]\n",
    "    val = len(new)\n",
    "    tam =str(val)\n",
    "    nominho = str(zero)\n",
    "\n",
    "    with open(r''+tam+ 'users '+ nominho +'samples.txt', 'w') as fp:\n",
    "        fp.write(str(new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| criar analize do menor numero de samples |\n",
    "\n",
    "User ylocu2a com 141 samples o que dão por volta de 2,8 segundos;\n",
    "\n",
    "Sera utilizado como media para o grupo inteiro usar 141 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('sensors/1tnew6a_1537303821892.json')\n",
    "ylocu2a = json.load(f)\n",
    "database = pd.DataFrame(ylocu2a['gyroscope'])\n",
    "database.drop([\"screen\"], axis=1, inplace=True)\n",
    "x = database[\"x\"].values\n",
    "y = database[\"y\"].values\n",
    "z = database[\"z\"].values\n",
    "ax = database.plot(linewidth=1, fontsize=10)\n",
    "# Additional customizations\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend(fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Analize da ID/ caminho definido pela time series em plot 3D |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Data for a three-dimensional line\n",
    "ax.plot3D(x, y, z)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# Data for three-dimensional scattered points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Generalização da leitura de todos os dados buscados no menor caso |\n",
    "\n",
    "Pegando os usuarios q de 'zeta' e j de toda a lista de timestem para quanto compativo adicionar ao novo dataset;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "h = 0\n",
    "b = 0\n",
    "\n",
    "chuck = []\n",
    "xe = [\"x\"]\n",
    "ye = [\"y\"]\n",
    "ze = [\"z\"]\n",
    "xi = [\"x\"]\n",
    "yi = [\"y\"]\n",
    "zi = [\"z\"]\n",
    "luck = []\n",
    "q = []\n",
    "z = zeta['user'].values\n",
    "g = gama['user'].values\n",
    "d = delta['user'].values\n",
    "q.extend(z)\n",
    "q.extend(g)\n",
    "q.extend(d)\n",
    "z = alfa['user'].values\n",
    "g = beta['user'].values\n",
    "d = celta['user'].values\n",
    "q.extend(z)\n",
    "q.extend(g)\n",
    "q.extend(d)\n",
    "s = sigma['user'].values\n",
    "q.extend(s)\n",
    "tamanho = 141\n",
    "window_size = 141\n",
    "\n",
    "for i in q:\n",
    "    time = True\n",
    "    rand = 1\n",
    "    #talvez por o false aqui\n",
    "    for j in tentando:\n",
    "        json_files = glob.glob('sensors/'+i+'_'+j+'.json')\n",
    "        if time == False:\n",
    "            break\n",
    "        for file in json_files:\n",
    "            x = 'sensors/'+i+'_'+j+'.json'\n",
    "            if time == False:\n",
    "                break\n",
    "            #if breck\n",
    "            if  x == file:\n",
    "                if time ==True:\n",
    "                    time = False\n",
    "                b = b+1\n",
    "                h = b/len(q)\n",
    "                print(h,\"%\")\n",
    "                f = open('sensors/'+i+'_'+j+'.json')\n",
    "                data = json.load(f)\n",
    "                df = pd.DataFrame(data['accelerometer'])\n",
    "                #c = scaler.transform(a)\n",
    "                \n",
    "                df = df.assign(user = ' '+i)\n",
    "                lenf = len(df)\n",
    "\n",
    "                df = df.iloc[0:200]\n",
    "                #criar 100-141 - 41 samples\n",
    "                #df2 = df.iloc[99:141]\n",
    "                df = df.drop(['screen'], axis=1)\n",
    "                #df2 = df2.drop(['screen'], axis=1)\n",
    "\n",
    "                \n",
    "                #criar dataframe/series - 100\n",
    "                xeq = df[\"x\"].values\n",
    "                xeq = np.array2string(xeq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                xe.append(xeq)\n",
    "                yeq = df[\"y\"].values\n",
    "                yeq = np.array2string(yeq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                ye.append(yeq)\n",
    "                zeq = df[\"z\"].values\n",
    "                zeq = np.array2string(zeq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                ze.append(zeq)\n",
    "                #Criar dataframe/series - 41\n",
    "                #xiq = df2[\"x\"].values\n",
    "                #xiq = np.array2string(xiq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                #xi.append(xiq)\n",
    "                #yiq = df2[\"y\"].values\n",
    "                #yiq = np.array2string(yiq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                #yi.append(yeq)\n",
    "                #ziq = df2[\"z\"].values\n",
    "                #ziq = np.array2string(ziq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                #zi.append(ziq)\n",
    "                if i == q[0]:\n",
    "                    database_re = df\n",
    "                #if i == q[0]:\n",
    "                #    re = df2\n",
    "                #frames = [re,df2]\n",
    "                #re = pd.concat(frames)\n",
    "                frames = [database_re, df]\n",
    "                database_re = pd.concat(frames)\n",
    "                chuck.append(i)\n",
    "                \n",
    "                #df2 = pd.DataFrame(data['accelerometer'])\n",
    "\n",
    "                #df2 = df2.iloc[k:randf]\n",
    "                #xiqq = df2[\"x\"].values\n",
    "                #xiqq = np.array2string(xiqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                #xi.append(xiqq)\n",
    "                #yiqq = df2[\"y\"].values\n",
    "                #yiqq = np.array2string(yiqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                #yi.append(yiqq)\n",
    "                #ziqq = df2[\"z\"].values\n",
    "                #ziqq = np.array2string(ziqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                #zi.append(ziqq)\n",
    "                #luck.append(i)\n",
    "\n",
    "                for k in range(199):\n",
    "\n",
    "                    randf = rand+200\n",
    "                    f = open('sensors/'+i+'_'+j+'.json')\n",
    "                    data = json.load(f)\n",
    "                    df = pd.DataFrame(data['accelerometer'])\n",
    "                    df = df.iloc[rand:randf]\n",
    "                    \n",
    "                    \n",
    "                    xeqq = df[\"x\"].values\n",
    "                    xeqq = np.array2string(xeqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    xe.append(xeqq)\n",
    "                    yeqq = df[\"y\"].values\n",
    "                    yeqq = np.array2string(yeqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    ye.append(yeqq)\n",
    "                    zeqq = df[\"z\"].values\n",
    "                    zeqq = np.array2string(zeqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    ze.append(zeqq)\n",
    "                    chuck.append(i)\n",
    "                    rand = rand+1\n",
    "            #if breack\n",
    "                #for k in range(439):\n",
    "                    #randf = k+150\n",
    "                    #f = open('sensors/'+i+'_'+j+'.json')\n",
    "                    #data = json.load(f)\n",
    "                    #df2 = pd.DataFrame(data['accelerometer'])\n",
    "\n",
    "                    #df2 = df2.iloc[k:randf]\n",
    "                    #xiqq = df2[\"x\"].values\n",
    "                    #xiqq = np.array2string(xiqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    #xi.append(xiqq)\n",
    "                    #yiqq = df2[\"y\"].values\n",
    "                    #yiqq = np.array2string(yiqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    #yi.append(yiqq)\n",
    "                    #ziqq = df2[\"z\"].values\n",
    "                    #ziqq = np.array2string(ziqq, separator=',', max_line_width=0, formatter={'float_kind': lambda x: \"%.10f\" % x}).replace('[', '').replace(']', '').replace('\\n', '').replace(' ', '')\n",
    "                    #zi.append(ziqq)\n",
    "                    #luck.append(i)\n",
    "\n",
    "            \n",
    "database_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Quantidade das janelas |\n",
    "\n",
    "A quantidade das janelas depende do tamanho das samples\n",
    "\n",
    "| Tamanho das janelas |\n",
    "\n",
    "ainda vamo ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_re.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q = zeta['usuario']\n",
    "#q.reset_index(drop=True, inplace=True)\n",
    "xe1 = pd.DataFrame(xe)\n",
    "ye1 = pd.DataFrame(ye)\n",
    "ze1 = pd.DataFrame(ze)\n",
    "xi1 = pd.DataFrame(xi)\n",
    "#xi1 = xi1.replace(\"x\",\"XA\")\n",
    "#yi1 = pd.DataFrame(yi)\n",
    "#yi1 = yi1.replace(\"y\",\"YA\")\n",
    "#zi1 = pd.DataFrame(zi)\n",
    "#zi1 = zi1.replace(\"z\",\"ZA\")\n",
    "frames = [xe1,ye1,ze1]\n",
    "train = pd.concat(frames, axis = 1)\n",
    "#print(len(xe))\n",
    "#print(len(xi))\n",
    "#frames = [xi1,yi1,zi1, train]\n",
    "#train = pd.concat(frames, axis = 1)\n",
    "train.columns = train.iloc[0]\n",
    "train = train.drop([0])\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train['label'] = chuck\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xe1 = pd.DataFrame(xe)\n",
    "ye1 = pd.DataFrame(ye)\n",
    "ze1 = pd.DataFrame(ze)\n",
    "xi1 = pd.DataFrame(xi)\n",
    "#xi1 = xi1.replace(\"x\",\"XA\")\n",
    "#yi1 = pd.DataFrame(yi)\n",
    "#yi1 = yi1.replace(\"y\",\"YA\")\n",
    "#zi1 = pd.DataFrame(zi)\n",
    "#zi1 = zi1.replace(\"z\",\"ZA\")\n",
    "frames = [xe1,ye1,ze1]\n",
    "test = pd.concat(frames, axis = 1)\n",
    "#frames = [xi1,yi1,zi1,test]\n",
    "\n",
    "#test = pd.concat(frames, axis = 1)\n",
    "#test.columns = test.iloc[0]\n",
    "test = test.drop([0])\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "test['label'] = chuck\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = train.sample(frac=1)\n",
    "\n",
    "teste = teste.iloc[:9750].reset_index(drop=True)\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'x': 'X', 'y': 'Y', 'z': 'Z'})\n",
    "#teste = test.rename(columns={'x': 'X', 'y': 'Y', 'z': 'Z','x': 'XA', 'y': 'YA', 'z': 'ZA'})\n",
    "train.to_csv('train_dataframe_gyro.csv', index=None, header=True, sep=':')\n",
    "#teste.to_csv('test_dataframe_gyro.csv', index=None, header=True, sep=':')\n",
    "train.to_csv('label_train.csv', index=None, header=True, sep=':')\n",
    "#teste.to_csv('label_test.csv', index=None, header=True, sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| FLOWER FRAMEWORK |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Plotar graficos de resultados |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import t\n",
    "import seaborn as sns \n",
    "desvio1 =[0]\n",
    "desvio2 =[0]\n",
    "desvio3 =[0]\n",
    "plt.figure(figsize=(120, 90))\n",
    "resnet = pd.read_csv('resnet.txt', sep=',')\n",
    "incep = pd.read_csv('inception.txt', sep=',')\n",
    "cnn = pd.read_csv('cnn.txt', sep=',')\n",
    "a = resnet.drop([\"frr\", \"recall\",\"precision\",\"accuracy\",\"fpr\",\"f1\",\"strategy\",\"nn\"], axis=1)\n",
    "b = incep.drop([\"frr\", \"recall\",\"precision\",\"accuracy\",\"fpr\",\"f1\",\"strategy\",\"nn\"], axis=1)\n",
    "c = cnn.drop([\"frr\", \"recall\",\"precision\",\"accuracy\",\"fpr\",\"f1\",\"strategy\",\"nn\"], axis=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlim(1,10)\n",
    "plt.ylim(0,2.5)\n",
    "\n",
    "ax.plot(a)\n",
    "ax.plot(b)\n",
    "ax.plot(c)\n",
    "ax.legend(['Resnet', 'Inception','Zhao'])\n",
    "ax.set_xlabel(\"Rounds\")\n",
    "ax.set_ylabel(\"LOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import t\n",
    "import seaborn as sns \n",
    "from statistics import median\n",
    "from math import isnan\n",
    "from itertools import filterfalse\n",
    "resnet=[]\n",
    "resnet2=[]\n",
    "incep = []\n",
    "incep2= []\n",
    "desvio1=[]\n",
    "desvio2=[]\n",
    "desvio3=[]\n",
    "desvio4=[]\n",
    "#rodadas =[1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,]\n",
    "rodadas =[1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,]\n",
    "#plt.figure(figsize=(120, 90))\n",
    "\n",
    "a = pd.read_csv('aggregation_eva_32batch_5epoch.txt', sep=',')\n",
    "a[\"rounds\"] = rodadas\n",
    "a = a.drop([\"frr\", \"recall\",\"precision\",\"accuracy\",\"fpr\",\"f1\",\"strategy\"], axis=1)\n",
    "b = pd.read_csv('aggregation_eva_32batch_10epoch.txt', sep=',')\n",
    "b[\"rounds\"] = rodadas\n",
    "b = b.drop([\"frr\", \"recall\",\"precision\",\"accuracy\",\"fpr\",\"f1\",\"strategy\"], axis=1)\n",
    "c = pd.read_csv('aggregation_eva_32batch_5epoch.txt', sep=',')\n",
    "c[\"rounds\"] = rodadas\n",
    "c = c.drop([\"frr\", \"recall\",\"precision\",\"accuracy\",\"fpr\",\"f1\",\"strategy\"], axis=1)\n",
    "e = pd.read_csv('aggregation_eva_32batch_10epoch.txt', sep=',')\n",
    "e[\"rounds\"] = rodadas\n",
    "e = e.drop([\"frr\", \"recall\",\"precision\",\"accuracy\",\"fpr\",\"f1\",\"strategy\"], axis=1)\n",
    "for i in range(1,11):\n",
    "    z = 1\n",
    "    re = a.loc[a['rounds']==i]\n",
    "    re = re.loc[re['nn']==\"resnet\"]\n",
    "    re = re.drop([\"nn\", \"rounds\"], axis =1)\n",
    "    re = re.values\n",
    "    l = (re.sum()/10)\n",
    "    d = (np.std(re))\n",
    "    #l = (re.sum()/10)*100\n",
    "    #d = (np.std(re))*100\n",
    "    desvio1.append(d)\n",
    "    resnet.append(l)\n",
    "    z = 1\n",
    "    re = b.loc[b['rounds']==i]\n",
    "    re = re.loc[re['nn']==\"resnet\"]\n",
    "    re = re.drop([\"nn\", \"rounds\"], axis =1)\n",
    "    re = re.values\n",
    "    l = (re.sum()/10)\n",
    "    d = (np.std(re))\n",
    "    #l = (re.sum()/10)*100\n",
    "    #d = (np.std(re))*100\n",
    "    desvio2.append(d)\n",
    "    resnet2.append(l)\n",
    "\n",
    "    z = 1\n",
    "    re = c.loc[c['rounds']==i]\n",
    "    re = re.loc[re['nn']==\"inception\"]\n",
    "    re = re.drop([\"nn\", \"rounds\"], axis =1)\n",
    "    re = re.values\n",
    "    l = (re.sum()/10)\n",
    "    d = (np.std(re))\n",
    "    #l = (re.sum()/10)*100\n",
    "    #d = (np.std(re))*100\n",
    "    desvio3.append(d)\n",
    "    incep.append(l)\n",
    "\n",
    "    z = 1\n",
    "    re = e.loc[e['rounds']==i]\n",
    "    re = re.loc[re['nn']==\"inception\"]\n",
    "    re = re.drop([\"nn\", \"rounds\"], axis =1)\n",
    "    re = re.values\n",
    "    l = (re.sum()/10)\n",
    "    d = (np.std(re))\n",
    "    #l = (re.sum()/10)*100\n",
    "    #d = (np.std(re))*100\n",
    "    desvio4.append(d)\n",
    "    incep2.append(l)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#plt.xlim(1,10)\n",
    "#plt.ylim(0,0.02)\n",
    "#ax.plot(resnet)\n",
    "#ax.plot(incep)\n",
    "#ax.plot(zhao)\n",
    "#ax.legend(['Resnet', 'Inception','Zhao'])\n",
    "#ax.plot(a)\n",
    "\n",
    "#ax.legend(['Inception'])\n",
    "#ax.set_xlabel(\"Rounds\")\n",
    "#ax.set_ylabel(\"FPR\")\n",
    "\n",
    "#centalizado accuracy\n",
    "#central = [0.9833333333333333, 0.9666666666666667, 0.9925833333333334, 0.9925, 0.90675, 1.0, 0.98125, 0.999, 0.986, 0.9929166666666667]\n",
    "\n",
    "#centalizado frr\n",
    "#central = [0.016666666666666666, 0.03333333333333333, 0.007416666666666667, 0.0075, 0.09325, 0.0, 0.01875, 0.001, 0.014, 0.007083333333333333]\n",
    "\n",
    "#centalizado fpr\n",
    "#central = [0.0002824858757062147, 0.0005649717514124294, 0.00012570621468926553, 0.0001271186440677966, 0.0015805084745762713, 0.0, 0.0003177966101694915, 0.0001694915254237288, 0.00023728813559322035, 0.00012005649717514124]\n",
    "\n",
    "#centalizado loss\n",
    "central = [0.029324986040592194, 0.05797344073653221, 0.013216694816946983, 0.046494465321302414, 0.32117292284965515, 0.013530018739402294, 0.047988880425691605, 0.013305929489433765, 0.07797975838184357, 0.012300330214202404]\n",
    "\n",
    "\n",
    "#cent = (sum(central)/10)*100\n",
    "cent = (sum(central)/10)\n",
    "print(cent)\n",
    "centra =[cent,cent,cent,cent,cent,cent,cent,cent,cent,cent]\n",
    "#centra=[0.1573,0.1573,0.1573,0.1573,0.1573,0.1573,0.1573,0.1573,0.1573,0.1573]\n",
    "\n",
    "#desvio5=[2.6142579146756835,2.6142579146756835,2.6142579146756835,2.6142579146756835,2.6142579146756835,2.6142579146756835,2.6142579146756835,2.6142579146756835,2.6142579146756835,2.6142579146756835]\n",
    "#desvio5=[2.6142579146756818,2.6142579146756818,2.6142579146756818,2.6142579146756818,2.6142579146756818,2.6142579146756818,2.6142579146756818,2.6142579146756818,2.6142579146756818,2.6142579146756818]\n",
    "#desvio5=[0.044309456180943767,0.044309456180943767,0.044309456180943767,0.044309456180943767,0.044309456180943767,0.044309456180943767,0.044309456180943767,0.044309456180943767,0.044309456180943767,0.044309456180943767]\n",
    "desvio5=[0.08859978750908175,0.08859978750908175,0.08859978750908175,0.08859978750908175,0.08859978750908175,0.08859978750908175,0.08859978750908175,0.08859978750908175,0.08859978750908175,0.08859978750908175]\n",
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "yr = resnet\n",
    "yi = resnet2\n",
    "yc = incep\n",
    "yd = incep2\n",
    "yf = centra\n",
    "diffr = desvio1\n",
    "diffi = desvio2\n",
    "diffc = desvio3\n",
    "diffd = desvio4\n",
    "difff = desvio5\n",
    "yerrr = diffr\n",
    "yerri = diffi\n",
    "yerrc = diffc\n",
    "yerrd = diffd\n",
    "yerrf = difff\n",
    "print(diffr)\n",
    "print(diffi)\n",
    "print(diffc)\n",
    "print(diffd)\n",
    "print(difff)\n",
    "plt.figure(figsize=(9, 5.5))\n",
    "plt.errorbar(x, yr , yerr = yerrr,\n",
    "\t\t\tlabel ='Resnet')\n",
    "plt.errorbar(x, yi , yerr = yerri,\n",
    "\t\t\tlabel ='Resnet2')\n",
    "plt.errorbar(x, yc , yerr = yerrc,\n",
    "\t\t\tlabel ='Incep',)\n",
    "plt.errorbar(x, yd , yerr = yerrd,\n",
    "\t\t\tlabel ='Incep2',)\n",
    "plt.errorbar(x, yf , yerr = yerrf,\n",
    "\t\t\tlabel ='central',)\n",
    "plt.xlim(1,10)\n",
    "plt.ylim(0,4.5)\n",
    "#loc='lower right'\n",
    "plt.legend(['ResNet 5 epochs', 'ResNet 10 epochs', 'Inception 5 epochs','Inception 10 epochs', 'Centralized'], prop={'size':20})\n",
    "plt.xlabel(\"Rounds\",fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel(\"Loss\", fontsize = 20)\n",
    "plt.savefig(\"FinalLoss.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('dolly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "501386ff6d6392c0d51ae1aa27a608490d0c48864a65e9a342737520f7110a67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
